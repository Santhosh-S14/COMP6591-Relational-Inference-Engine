#!/usr/bin/env python
# coding: utf-8

# In[1]:


from pyswip.prolog import PrologError
from transformers import AutoModelForSeq2SeqLM, AutoTokenizer
import os
from pyswip import Prolog

tokenizer = AutoTokenizer.from_pretrained("Babelscape/rebel-large")
model = AutoModelForSeq2SeqLM.from_pretrained("Babelscape/rebel-large")


# In[2]:


def extract_relations_from_model_output(text):
    relations = []
    relation, subject, relation, object_ = '', '', '', ''
    text = text.strip()
    current = 'x'
    text_replaced = text.replace("<s>", "").replace("<pad>", "").replace("</s>", "")
    print(text_replaced)
    for token in text_replaced.split():
        if token == "<triplet>":
            current = 't'
            if relation != '':
                relations.append({
                    'head': subject.strip(),
                    'type': relation.strip(),
                    'tail': object_.strip()
                })
                relation = ''
            subject = ''
        elif token == "<subj>":
            current = 's'
            if relation != '':
                relations.append({
                    'head': subject.strip(),
                    'type': relation.strip(),
                    'tail': object_.strip()
                })
            object_ = ''
        elif token == "<obj>":
            current = 'o'
            relation = ''
        else:
            if current == 't':
                subject += ' ' + token
            elif current == 's':
                object_ += ' ' + token
            elif current == 'o':
                relation += ' ' + token
    if subject != '' and relation != '' and object_ != '':
        relations.append({
            'head': subject.strip(),
            'type': relation.strip(),
            'tail': object_.strip()
        })
    return relations


# In[3]:


class KB():
    def __init__(self):
        self.relations = []

    def are_relations_equal(self, r1, r2):
        return all(r1[attr] == r2[attr] for attr in ["head", "type", "tail"])

    def exists_relation(self, r1):
        return any(self.are_relations_equal(r1, r2) for r2 in self.relations)

    def merge_relations(self, r1):
        r2 = [r for r in self.relations
              if self.are_relations_equal(r1, r)][0]
        spans_to_add = [span for span in r1["meta"]["spans"]
                        if span not in r2["meta"]["spans"]]
        r2["meta"]["spans"] += spans_to_add

    def add_relation(self, r):
        if not self.exists_relation(r):
            self.relations.append(r)
        else:
            self.merge_relations(r)

    def print(self):
        print("Relations:")
        for r in self.relations:
            print(f"  {r}")


# In[19]:


def from_text_to_kb(text, span_length=26, verbose=False):
    # tokenize whole text
    inputs = tokenizer([text], return_tensors="pt")

    # compute span boundaries
    num_tokens = len(inputs["input_ids"][0])
    if verbose:
        print(f"Input has {num_tokens} tokens")
    num_spans = math.ceil(num_tokens / span_length)
    if verbose:
        print(f"Input has {num_spans} spans")
    overlap = math.ceil((num_spans * span_length - num_tokens) /
                        max(num_spans - 1, 1))
    spans_boundaries = []
    start = 0
    for i in range(num_spans):
        spans_boundaries.append([start + span_length * i,
                                 start + span_length * (i + 1)])
        start -= overlap
    if verbose:
        print(f"Span boundaries are {spans_boundaries}")

    # transform input with spans
    tensor_ids = [inputs["input_ids"][0][boundary[0]:boundary[1]]
                  for boundary in spans_boundaries]
    tensor_masks = [inputs["attention_mask"][0][boundary[0]:boundary[1]]
                    for boundary in spans_boundaries]
    inputs = {
        "input_ids": torch.stack(tensor_ids),
        "attention_mask": torch.stack(tensor_masks)
    }

    # generate relations
    num_return_sequences = 3
    gen_kwargs = {
        "max_length": 514,
        "length_penalty": 0,
        "num_beams": 3,
        "num_return_sequences": num_return_sequences
    }
    generated_tokens = model.generate(
        **inputs,
        **gen_kwargs,
    )

    # decode relations
    decoded_preds = tokenizer.batch_decode(generated_tokens,
                                           skip_special_tokens=False)

    # create kb
    kb = KB()
    i = 0
    for sentence_pred in decoded_preds:
        current_span_index = i // num_return_sequences
        relations = extract_relations_from_model_output(sentence_pred)
        for relation in relations:
            relation["meta"] = {
                "spans": [spans_boundaries[current_span_index]]
            }

            kb.add_relation(relation)
        i += 1
    kb.print()
    return kb


# In[24]:


text = """Napoleon Bonaparte was born on 15 August 1769. Napoleon Bonaparte was a French military
and political leader who rose to prominence during the French Revolution and led
several successful campaigns during the Revolutionary Wars. He was the de facto
leader of the French Republic as First Consul from 1799 to 1804. As Napoleon Bonaparte,
he was Emperor of the French from 1804 until 1814 and again in 1815. Napoleon's
political and cultural legacy has endured, and he has been one of the most 
celebrated and controversial leaders in world history. Napoleon Bonaparte was died on 15 May 1821 """

# In[25]:


import math
import torch

kb = from_text_to_kb(text, verbose=False)
try:
    os.remove("facts.pl")
except OSError:
    pass
for relation in kb.relations:
    relation['type'] = relation['type'].replace(" ", "")
    relation['head'] = relation['head'].replace(" ", "")
    relation['tail'] = relation['tail'].replace(" ", "")
    relation['tail'] = "\"" + relation['tail'] + "\""
    with open('facts.pl', 'a') as f:
        f.write(relation['type'] + "(" + relation['head'].lower() + "," + relation['tail'].lower() + ").\n")

# In[26]:


# q = " What is the date of birth of Napoleon Bonaparte? "
# q = " What is the date of birth of Napoleon Bonaparte? "
# q = " When was Napoleon Bonaparte born on? "
# q = " Which revolutionary wars was he part of? "
q = " What was the position held by Napoleon Bonaparte? "
kbQ = from_text_to_kb(q, verbose=False)
queries = []
for r in kbQ.relations:
    r['type'] = r['type'].replace(" ", "")
    r['head'] = r['head'].replace(" ", "")
    r['tail'] = r['tail'].replace(" ", "")
    q = r['type'] + "(" + r['head'].lower() + "," + "X" + ")"
    queries.append(q)
    q = r['type'] + "(" + r['tail'].lower() + "," + "X" + ")"
    queries.append(q)
    q = r['head'] + "(" + r['tail'].lower() + "," + "X" + ")"
    queries.append(q)
    q = r['head'] + "(" + r['type'].lower() + "," + "X" + ")"
    queries.append(q)
    q = r['type'] + "(" + r['tail'].lower() + "," + "X" + ")"
    queries.append(q)
    q = r['type'] + "(" + r['head'].lower() + "," + "X" + ")"
    queries.append(q)
    q = r['type'] + "(" + "X" + "," + "\"" + r['head'].lower() + "\"" + ")"
    queries.append(q)
    q = r['type'] + "(" + "X" + "," + "\"" + r['tail'].lower() + "\"" + ")"
    queries.append(q)
    q = r['head'] + "(" + "X" + "," + "\"" + r['tail'].lower() + "\"" + ")"
    queries.append(q)
    q = r['head'] + "(" + "X" + "," + "\"" + r['type'].lower() + "\"" + ")"
    queries.append(q)
    q = r['type'] + "(" + "X" + "," + "\"" + r['tail'].lower() + "\"" + ")"
    queries.append(q)
    q = r['type'] + "(" + "X" + "," + "\"" + r['head'].lower() + "\"" + ")"
    queries.append(q)
c = "null"
prolog = Prolog()
prolog.consult("facts.pl")
for q in queries:

    try:
        if list(prolog.query(q)):
            c = (list(prolog.query(q)))
    except PrologError:
        pass
print(c)

# In[ ]:


# In[ ]:
